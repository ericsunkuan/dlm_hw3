data:
  batch_size: 64
  data_dir: src/data/Pop1K7
  num_workers: 4
  sequence_length: 512
  vocab_size: 512

model:
  d_model: 512
  n_head: 8
  n_layers: 12
  d_ff: 2048
  dropout: 0.1
  mem_len: 512

training:
  epochs: 100
  eval_every_n_steps: 1000
  fp16: true
  gradient_clip_val: 1.0
  learning_rate: 0.0001
  log_every_n_steps: 100
  save_every_n_steps: 5000
  warmup_steps: 1000

generation:
  max_length: 2048
  num_samples: 20
  temperatures:
    - 0.8
    - 1.0
    - 1.2
  top_k:
    - 20
    - 40
    - 60
